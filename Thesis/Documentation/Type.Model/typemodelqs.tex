\nonstopmode  % to allow pdflatex to compile even if errors are raised (e.g. missing figures)

\documentclass[10pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{graphicx}
% \graphicspath{{./figures/}} % save all figures in the same directory
\usepackage{color} 
\usepackage{hyperref}
\usepackage{parskip}
\setlength{\parindent}{0pt}

% Text layout
\topmargin 0.0cm
\oddsidemargin 0.5cm
\evensidemargin 0.5cm
\textwidth 16cm 
\textheight 21cm

%% PLEASE INCLUDE ALL MACROS BELOW
\newcommand{\etal}{\textit{et al.}} % use as "\etal{}" in citations
%\newcommand{\Prob}{\mathbb{P}} % symbol for proba
\newcommand{\Prd}{\mathsf{P}} % symbol for discrete proba
\newcommand{\Exp}{\mathbb{E}} % symbol for expectation
\newcommand{\Var}{\mathbb{V}} % symbol for variance
\newcommand{\Cov}{\mathbb{C}} % symbol for covariance
\newcommand{\Norm}{{\mathcal{N}}} % symbol for Normal distribution
\newcommand{\BF}{{\text{BF}}} % symbol for Bayes factor
\newcommand{\Lik}{{\mathcal{L}}} % symbol for likelihood
\newcommand{\bma}{{\BF_\text{BMA}}}
\newcommand{\bmalite}{{\BF_\text{BMAlite}}}
\newcommand{\av}{\mbox{\boldmath$\alpha$}}
\newcommand{\dv}{\bm{d}}
\newcommand{\der}{{\text{d}}} % "derivation" symbol inside integrals
\newcommand{\bv}{\mbox{\boldmath$\beta$}}
\newcommand{\tauv}{\mbox{\boldmath$\tau$}}
\newcommand{\cv}{\mbox{\boldmath$c$}}
\newcommand{\bbv}{\tilde \bv}
\newcommand{\bev}{\mbox{\boldmath$b$}}
\newcommand{\ev}{\mbox{\boldmath$e$}}
\newcommand{\thv}{\mbox{\boldmath$\theta$}}
\newcommand{\tv}{\mbox{\boldmath$t$}}
\newcommand{\fv}{\mbox{\boldmath$f$}}
\newcommand{\Cv}{\mbox{\boldmath$C$}}
\newcommand{\Dv}{\mbox{\boldmath$D$}}
\newcommand{\Fv}{\mbox{\boldmath$F$}}
\newcommand{\gav}{\mbox{\boldmath$\gamma$}}
\newcommand{\Gav}{\mbox{\boldmath$\Gamma$}}
\newcommand{\Kv}{\mbox{\boldmath$K$}}
\newcommand{\iv}{\mbox{\boldmath$I$}}
\newcommand{\vv}{\mbox{\boldmath$v$}}
\newcommand{\pv}{\mbox{\boldmath$p$}}
\newcommand{\hv}{\mbox{\boldmath$h$}}
\newcommand{\gv}{\mbox{\boldmath$g$}}
\newcommand{\wv}{\mbox{\boldmath$w$}}
\newcommand{\Wv}{\mbox{\boldmath$W$}}
\newcommand{\Pv}{\mbox{\boldmath$P$}}
\newcommand{\Qv}{\mbox{\boldmath$Q$}}
\newcommand{\Rv}{\mbox{\boldmath$R$}}
\newcommand{\rv}{\mbox{\boldmath$r$}}
\newcommand{\sv}{\mbox{\boldmath$s$}}
\newcommand{\Sv}{\mbox{\boldmath$S$}}
\newcommand{\Sigv}{\mbox{\boldmath$\Sigma$}}
\newcommand{\qv}{\mbox{\boldmath$q$}}
\newcommand{\Mv}{\mbox{\boldmath$M$}}
\newcommand{\mv}{\mbox{\boldmath$\mu$}}
\newcommand{\mvg}{\mbox{\boldmath$\mu_g$}}
\newcommand{\Lv}{\mbox{\boldmath$L$}}
\newcommand{\lav}{\mbox{\boldmath$\lambda$}}
\newcommand{\tr}{{\text{tr}}}
\newcommand{\Tv}{\mbox{\boldmath$T$}}
\newcommand{\Xv}{\mbox{\boldmath$X$}}
\newcommand{\xv}{\mbox{\boldmath$x$}}
\newcommand{\Uv}{\mbox{\boldmath$U$}}
\newcommand{\Vv}{\mbox{\boldmath$V$}}
\newcommand{\yv}{\mbox{\boldmath$y$}}
\newcommand{\Sr}{\mbox{\boldmath$\Sigma$}}

\newcommand{\yvg}{\mbox{\boldmath$y_g$}}
\newcommand{\Yv}{\mbox{\boldmath$Y$}}
\newcommand{\Zv}{\mbox{\boldmath$Z$}}
\newcommand{\zv}{\mbox{\boldmath$z$}}
\newcommand{\lv}{\bf{1}}
\newcommand{\muLS}{\ensuremath{\hat{\mv}}}
\newcommand{\SigmaLS}{\ensuremath{\hat{\Sigma}}}
\newcommand{\fvPanel}{\ensuremath{\fv^{\rm panel}}}
\newcommand{\isa}{\ensuremath{\sigma_a^{-2}}}
\newcommand{\bfa}{\ensuremath{{\rm BF}}}
\newcommand{\hbfes}{\ensuremath{\widehat {\rm BF}^{\rm ES}}}
\newcommand{\hbfesmeta}{\ensuremath{\widehat {{\rm BF}}^{\rm ES}_{\rm meta}}}
\newcommand{\hbfesfix}{\ensuremath{\widehat {{\rm BF}}^{\rm ES}_{\rm fix}}}
\newcommand{\hbfesmax}{\ensuremath{\widehat {{\rm BF}}^{\rm ES}_{\rm maxH}}}
\newcommand{\hbfee}{\ensuremath{ \widehat {\rm BF}^{\rm EE} }}
\newcommand{\abfes}{\ensuremath{{\rm ABF^{ES}}}}
\newcommand{\abfee}{\ensuremath{{\rm ABF^{EE}}}}
\newcommand{\abfesc}{\ensuremath{{\rm A^*BF^{ES}}}}


%% END MACROS SECTION

\begin{document}

\title{Statistical inference of eQTL sharing among a high number of tissues}
\author{Timoth\'{e}e Flutre, Sarah Urbut, Xiaoquan Wen, Matthew Stephens}
\date{\today}

\maketitle

%\tableofcontents

\vspace{1cm}

This document describes the ``type'' model, an extension of the ``config'' model in details in the document ``config\_model.tex/pdf'' available in the private repository \href{https://github.com/stephenslab/paper-eQtlBma}{paper-eQtlBma} on GitHub.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Motivation}

\begin{itemize}
\item Pending question from last time: Where does the MLE of the covariance in effects come from with summary stats of different tissues? (i.e., in our Config model document, the off-dagonal elements of $\hat V_{gp}$) See SS.ex in the posterior.effect.size simulation?

\item{\textbf{Answer (per William)}} This is indeed an issue. In the meta-anlysis case, this is actually always the case because we have no information about the covariance in standard errors of effect sizes from the data. However, the use of a prior which assumes some cross-tissue covariance (i.e., $\omega$ is non-zero) captures some of the `` true '' underlying tissue covariance. From the AoAS paper below:
\begin{figure}[h]
\includegraphics[scale=0.85]{b_bar.pdf}
\end{figure}

Note that the standard error of the fixed effect, $\zeta$, is really just the sum of the individual study-specific standard error  of the effects and each tissue-specific prior covariance term. Obviously, if the data is acquired from multiple outside studies, we would have no information about the effect size covariance. But more generally, we know that the residual matrix $\hat\Sr$ is relatively sparse (as also induced in our tutorial), then the effect-size covariance matrix $\hat\Vv$(simply $\mathbf X ' \mathbf X \times \hat \Sr$, will also be relatively sparse. \emph{So is the only information we have about shared effects is in the prior which we induce.?} No -- again, the information about shared effect comes from the grid weight estimation which, if the effects are shared among tissues, will tend to put more weight on larger values of $\omega$. The sparse covariance matrix of standard errors simply suggests that the errors of the estimates are not correlated among tissues. 

Similarly, I ascertained that the reason we can separate this into the product of the $\hbfesfix$ and $\hbfesmeta$ is because we assume the studies and the corresponding residuals are independent, which is effectively our situation if I assume the above correctly. Thus we are no longer interested in the multivariate distribution of effects across tissues, i.e., the vector $\mathbf \beta$, but rather the product of the univariate effects, correct? I think this is the assumption we make by setting $\omega^{2}$ to 0 in v1. \emph{So are we making inference on a multivariate $\beta$ in the BF or the product of many univariate (as in AoAS)} $\textbf{The reason that we are still interested in the joint inference even as a product of univariate if the mean effect is zero is that we will still get information on the consistency of configuration (i.e., the weight $\eta$) and the sample size achievement.}$
Matthew wrote that:

\item \emph {By modeling the sharing of active eQTLs among tissues, this framework increases power to detect eQTLs that are present in more than one tissue compared with “tissue-by-tissue” analyses that examine each tissue separately" - the type model (without correlations) is still modelllng the *sharing* of eQTLs among tissues (i.e presence/absence of eQTLs among tissues). It just isn't modeling the similarity of the effects.}

So then the advantage of the analysis is that if we consider the ABF for a model in which we have information on 5 tissues, and the sample size for one tissue is smaller, the evidence that a SNP is active in the smaller-sample size tissue will be augmented by the additional information from the more-easily ascertained tissue, analogous to the configuration model. The difference is that we ignore the sharing of effect, and so it is not necessary to pull the integrals back together (as in AoAS paper equation A.6, and see my 'Understanding the Config Model.pdf'). \textbf{This also assumes that not only the tissues but the effect sizes are independent among tissues, because we use $\hat \beta_{r}$ as a summary for $\textbf{Y}$ and thus if the gene expression readings for each element of  $\textbf{Y}$  are i.i.d., so are the $\hat \beta_{r}$?}

\item {\emph Note that the first version of the ``type'' model (currently implemented in the eQtlBma package) drastically simplifies this sum by only considering the consistent configuration.}

So is this analogous to assuming that in:

\begin{equation}
  \label{bf_gpkl}
  \begin{aligned}
    \BF_{gpkl}(\bm{q}_k,\omega_l,\phi_l) &= \frac{p(Y_g | \Xv_{gp}, t_{gpk}=1, d_{gpl}=1)}{p(Y_g | \Xv_{gp}, z_g=0)} \\
    &= \frac{\int p(Y_g | \Xv_{gp}, \bm{\mu}, \bm{b}, \Sigma) \; p(\bm{\mu},\Sigma) \; p(\bm{b} | \bm{q}_k, \omega_l, \phi_l) \; \der \bm{b} \; \der \bm{\mu} \; \der \Sigma}{\int p(Y_g | \Xv_{gp}, \bm{\mu}, \bm{b}=\bm{0}, \Sigma) \; p(\bm{\mu},\Sigma) \; \der \bm{\mu} \; \der \Sigma}
  \end{aligned}
\end{equation}

both $\Sigma$ (the covariance in residuals errors) and the the corresponding $\mathbf X ' \mathbf X \times \hat \Sr$ (i.e., the true covariance in effects) are diagonal and non-singular (i.e., every diagonal entry complete) matrices, allowing us to factor the BF and use study-specific error approximations? Note that we write: 

\emph {In the scale-invariance formulation, we have $\bm{b} = diag(\Sigma)^{-\frac{1}{2}} \bm{\beta}$, so that $\bm{b}|\bm{q}_k \sim \Norm_R(\bm{0}, U_k)$ induces the prior $\bm{\beta}|\bm{q}_k \sim \Norm_R(\bm{0}, W_k)$ where $W_k = diag(\Sigma)^{-\frac{1}{2}} U_k diag(\Sigma)^{-\frac{1}{2}}$.}

\textbf {thus cementing my questions that if we assume the residuals between tissues are independent, so are the effect-sizes!} From page 5: \emph{note that we also have to assume that the errors are independent between tissues}): I notice that different from the AoAS paper, we integrate over one $\tau$ rather than a $\tau$ specific for each tissue - but where do we get the information in the likelihood to reinforce the covariance in effects (i.e., $\delta^2 = \frac{1}{\bm{g}^T \bm{g} - N \bar{g}^2}$) 

\textbf {Ahh no! The covariance in effects is reflected in similar $\beta_{s}$, which is captured by larger weights $\lambda_{l}$ on the grid which puts a lot of weight on non-zero shared effects (i.e., big $\omega$) and perhaps small $\phi$, suggesting that most tissues are derived from some underlying mean effects with little variance. In fact, the tissue expression could be perfectly correlated while the matrix of residuals sum of squares (and the corresponding residual standard error) could be very sparse - these two things are not related. My problem has been in conflating correlated residual standard error with correlated gene expression - variance reflects the deviation from the mean present among the data, while the residual sum of squares merely reflects deviation from the fit. There could be a perfect fit (i.e., very low RSS) that captures huge variability in the data. Just because the 'errors are independent between tissues' and thus the standard errors of effect size are independent between tissues does not mean that the effects are uncorrected - rather, their relative error in estimation is uncorrelated between tissues}

	
\item Why consider tissues jointly if shared effect is zero? \textbf{ We can still learn about the consistency of effects (i.e., the weight on the consistent config) and the sample size help.}

\item \emph{Most importantly, we assume that, given a type, the activity of an eQTL in tissue $r$ is independent from its activity in other tissues}

\item Yes: given a type, the Bayes factor for a vector (i.e., across all tissues) of expression is the product of the BF in each tissues. Because $\beta_{s}$ is always drawn conditional on $\gamma_{gar}$ = 1, once we have this product, we must integrate out $\gamma_{gppr}$, which crucially can be done in a univariate manner since we no longer have to consider the joint probability of a full configuration but rate rthe tissue-specific probability of being on or off (i.e., $q_{kr}$). This avoids also the problem of only considering the consistent configuration.

\begin{equation}
  \begin{aligned}
    \BF_{gpkl}(\bm{q}_k, \omega_l, \phi_l) &= \frac{\int p(\bar{b}_{gpl}) \; \prod_r p(\yv_{gr} | \Xv_{gp}, t_{gpk}=1, d_{gpl}=1, \bar{b}_{gpl}) \; \der \bar{b}_{gpl}}{\prod_r p(\yv_{gr} | \Xv_{gp}, z_g=0)} \\
    &= \frac{\int p(\bar{b}_{gpl}) \; \prod_r [ q_{kr} p(\yv_{gr} | \Xv_{gp}, d_{gpl}=1, \bar{b}_{gpl}, \gamma_{gpr}=1) + (1-q_{kr}) p(\yv_{gr} | \Xv_{gp}, \gamma_{gpr}=0) ] \; \der \bar{b}_{gpl}}{\prod_r p(\yv_{gr} | \Xv_{gp}, z_g=0)} \\
    &= \int_{-\infty}^{+\infty} f(\bar{b}_{gpl}, \bm{q}_k, \omega_l, \phi_l) \; \der \bar{b}_{gpl}
  \end{aligned}
\end{equation}

\item However, does this still allow us to exploit the shared effect among tissues? For example, in the $\textbf{Likeilhood of the Whole Data Set pdf}$, equation (5) and (6) show that the prior covariance matrix is indexed by configurations.
\end{itemize}

\begin{equation}
  \bm{b}_{gp} | U_{0} \sim \Norm_R(\bm{0}, U_{0})
\end{equation}
where, following Wen (2014), $U_{0}$ is parametrized as $(\Gamma_{gp},\Delta_{gp})$:
\begin{equation}
  p(U_{0}) = p(\Delta_{gp} | \Gamma_{gp}) \Prd(\Gamma_{gp})
\end{equation}
so that $\Gamma_{gp}$ is a binary matrix consisting of entry-wise non-zero indicators and is identical in size and layout to $U_{0}$, and $\Delta_{gp}$ is an indexed set of numerical values quantifying each non-zero entry in $\Gamma_{gp}$.
The skeleton $\Gamma_{gp}$ has $\bm{\gamma}_{gp}$ on the diagonal. Each off-diagonal entry $\Gamma_{gp,ij}$ is equal to 1 has long as diagonal elements $\Gamma_{gp,ii}$ and $\Gamma_{gp,jj}$ are both equal to 1.

\item \textbf{Yes - the shared effect among tissues will still be captured in the M step of the EM algorithm which will have larger BF when the effect sizes are similar (i.e., $\omega$ is non-zero ) and the corresponding grid weight.}

\begin{itemize}

\item Doesn't saying that given a type, the activity of an eQTL in tissue is independent from its activity in other tissues directly negate the covariance in effects?

\textbf {No - the phrase refers to the fact that given a type, the binary indicator $\gamma_{r}$ is independent of the other tissues, but the effects are still correlated conditional on $\gamma_{r}$ (per William) with covariance matrix $\mathbf W$. We integrate over all $\mathbf \gamma$ below.}

\item In the config model, given a configuration $\gav$, where we use an unknown mean $\bar{b}_{gp}$ to borrow information across tissues in which the eQTL is active. 
\begin{equation}
  b_{gpr} | \gamma_{gpr}, \bar{b}_{gp}, \phi \sim \gamma_{gpr} \Norm(\bar{b}_{gp}, \phi^2) + (1 - \gamma_{gpr}) \delta_0
\end{equation}

\end{itemize}

\textbf{By setting $\omega^{2}$ = 0, aren't we effectively curtailing our ability to "borrow information across tissues in which the eQTL is active"?}


But here, according to Solution (1) of the document, 

The target distribution $\bm{b} | \bm{q}_k$ can thus be approximated by the $\Norm_R(0,U_k)$ where:
\[
U_k = 
\begin{pmatrix}
  q_{k1} (\phi_l^2 + q_{k1} \omega_l^2) & \cdots & q_{k1} q_{kR} \omega_l^2 \\
  \vdots & \ddots & \vdots \\
  \cdots & \cdots & q_{kR} (\phi_l^2 + q_{kR} \omega_l^2)
\end{pmatrix}
\]

%Since the fact that there are non-zero entries on the diagonal means that the convariance is non-zero and beta is a multivariate normal, doesn't b|q mean that the effects are $\emph{ not independent conditional on type}$? So are we always left with the BF conditional on q, or do we ever integrate out q?

%I see in solution 2, we are effectively doing as in the supplement of the AOAS paper (i.e., equation A.6)




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Question}


In the type-based model, we use a latent indicator $K$-dimensional vector $\tv_{gp}$ to denote the actual type.
In case the SNP is not an eQTL,
\begin{equation}
  \Prd(\tv_{gp} = \bm{0}  | v_{gp} = 0) = 1.
\end{equation}
Otherwise, we assume the gene-SNP pair belongs to the $k$-th type with prior probability
\begin{equation}
  \Prd(t_{gpk} = 1 | v_{gp} = 1) = \pi_k
\end{equation}
with the constraints $\forall k \; \pi_k \ge 0$ and $\sum_k \pi_k = 1$.
All column vectors $\tv_{gp}$ for all $m_g$ SNPs are gathered into a $K \times m_g$ matrix $T_g$.

In the type-based model, we also index all tissues in which the eQTL is active via a latent indicator $R$-dimensional vector $\gav_{gp}$, which hence corresponds to its configuration.
However, compare to the ``config'' model where $\gav_{gp}$ simply corresponds to the latent variable $\cv_{gp}$ indexing the configuration, we now put a prior on $\gav_{gp}$.
In case the SNP is not an eQTL,
\begin{equation}
  \Prd(\gav_{gp} = \bm{0}  | \tv_{gp} = \bm{0}) = 1.
\end{equation}
Otherwise, we assume the eQTL is active in the $r$-th tissue with prior probability depending on the type
\begin{equation}
  \Prd(\gamma_{gpr} = 1 | t_{gpk} = 1) = q_{kr},
\end{equation}
for which we could also parametrize the $q_{kr}$ in terms of tissue-specific annotations, e.g. DNase peaks, and therefore have $q_{pkr}$.
Joining the column vectors $\gav_{gp}$ for all $K$ types, we obtain a latent $R \times K$ matrix $\Gamma_{gp}$.
All these matrices are gathered into $\Gav_g = (\Gamma_{g1},\ldots,\Gamma_{gm_g})$.
As a result, this bypasses the need for the $J$-dimensional vectors $\cv_{gp}$ where $J=2^R-1$ and the corresponding prior probabilities (the $\eta_j$'s).

\begin{itemize}
\item I understand that the  $K \times m_g$ matrix $T_g$ represents the identity of each SNP in the columns, so that the column sum is equal to 1 and the row sum is equal to the number of SNPs in the class. 

\item  Furthermore, the $R \times K$ matrix $\Gamma_{gp}$ represents the tissue-specific patterns of expression for each class across tissues, such that the column sums will represent the number of tissues a SNP of type 'k' might be active and the rows reprsent the total number of types from which a tissue derives activity. 

\item However, since the matrix  $\Gamma_{gp}$ is the same for all SNPs of a particular type, why is it necessary to stack the  $\Gamma_{gp}$ into  $\Gav_g?
\end{itemize}

\textbf{Answer
 The answer is that even if two SNPs are of the same type, suppose that the q vector for a particular type is [0.10 0.95 0.05 0.95 0.95]. One SNP could be [1 1 0 1 1] and one SNP could be [0 1 0 1 1] (although the second case is more likely)}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\section{Focus on a single gene-SNP pair}
%
%See the corresponding section in the document ``config\_model.tex/pdf''.
%
%
%\subsection{Introducing types in the Bayes factor}
%
%From the hierarchical model above, we can write the Bayes factor measuring the support in the data for the pair made of gene $g$ and SNP $p$ to be an eQTL in at least one tissue, $\BF_{gp}$.
%
%In the configuration model, we average over the configurations and the grid:
%\begin{equation}
%  \begin{aligned}
%    \BF_{gp}(\bm{\eta}, \bm{\lambda}) = \sum_{j,l} \; \eta_j \; \lambda_l \; \BF_{gpjl}(\omega_l,\phi_l)
%  \end{aligned}
%\end{equation}
%where
%\begin{equation}
%  \begin{aligned}
%    \BF_{gpjl}(\omega_l,\phi_l) &= \frac{p(Y_g | \Xv_{gp}, c_{gpj}=1, d_{gpl}=1)}{p(Y_g | \Xv_{gp}, z_g=0)} \\
%    &= \frac{\int p(Y_g | \Xv_{gp}, \bm{\mu}, \bm{b}, \Sigma) \; p(\bm{\mu},\Sigma) \; p(\bm{b} | \bm{\gamma}, \omega_l, \phi_l) \; \der \bm{b} \; \der \bm{\mu} \; \der \Sigma}{\int p(Y_g | \Xv_{gp}, \bm{\mu}, \bm{b}=\bm{0}, \Sigma) \; p(\bm{\mu},\Sigma) \; \der \bm{\mu} \; \der \Sigma}
%  \end{aligned}
%\end{equation}
%This Bayes factor can be calculated analytically using the Laplace approximation from Wen \& Stephens (AoAS 2014, if individuals are different between tissues) or from Wen (Biometrics 2014, if individuals are shared between tissues).
%
%\bigskip
%
%In the type model, we would first average over the types and the grid:
%\begin{equation}
%  \begin{aligned}
%    \BF_{gp}(\bm{\pi}, \bm{\lambda}, Q) = \sum_{k,l} \; \pi_k \; \lambda_l \; \BF_{gpkl}(\bm{q}_k,\omega_l,\phi_l)
%  \end{aligned}
%\end{equation}
%where
%\begin{equation}
%  \label{bf_gpkl}
%  \begin{aligned}
%    \BF_{gpkl}(\bm{q}_k,\omega_l,\phi_l) &= \frac{p(Y_g | \Xv_{gp}, t_{gpk}=1, d_{gpl}=1)}{p(Y_g | \Xv_{gp}, z_g=0)} \\
%    &= \frac{\int p(Y_g | \Xv_{gp}, \bm{\mu}, \bm{b}, \Sigma) \; p(\bm{\mu},\Sigma) \; p(\bm{b} | \bm{q}_k, \omega_l, \phi_l) \; \der \bm{b} \; \der \bm{\mu} \; \der \Sigma}{\int p(Y_g | \Xv_{gp}, \bm{\mu}, \bm{b}=\bm{0}, \Sigma) \; p(\bm{\mu},\Sigma) \; \der \bm{\mu} \; \der \Sigma}
%  \end{aligned}
%\end{equation}
%
%But then, in the ``naive'' version of the type model, we also have to average over all configurations possibly generated by type $k$ (via its $\bm{q}_k$) in the numerator of the Bayes factor:
%\begin{equation}
%  \label{avg_b_config}
%  p(\bm{b} | \bm{q}_k, \omega_l, \phi_l) = \sum_{j=1}^J \Prd(\bm{\gamma} | \bm{q}_k) \; p(\bm{b} | \bm{\gamma}, \omega_l, \phi_l)
%\end{equation}
%which is clearly intractable when $J=2^R-1$ is large.
%
%Note that the first version of the ``type'' model (currently implemented in the eQtlBma package) drastically simplifies this sum by only considering the consistent configuration.
%
%
%\subsection{Solution 1: average over all configurations per type}
%
%William proposed to approximate $\bm{b} | \bm{q}_k$ \eqref{avg_b_config} with a multivariate Normal by matching the first two moments (as we can calculate them analytically, see below).
%We already know that the priors are $\forall r \; b_r|\bar{b},\gamma_r \sim \gamma_r \Norm(\bar{b},\phi_l^2) + (1-\gamma_r) \delta_0$, $\bar{b} \sim \Norm(0,\omega_l^2)$ and $\gamma_r \sim \mathcal{B}(q_{kr})$.
%Using the laws of total expectations, variances and covariances, we first average over the possible values of $\bm{\gamma}$ as parametrized by $\bm{q}_k$, conditional on $\bar{b}$:
%\[
%\Exp[b_r \; | \; q_{kr}, \bar{b}] = \Exp[ \Exp[b_r | q_{kr}, \bar{b}, \gamma_r] ] = \Exp[\gamma_r \bar{b} | q_{kr}] = \bar{b} q_{kr}
%\]
%\[
%\Var[b_r \; | \; q_{kr}, \bar{b}] = \Exp[\Var[b_r | q_{kr}, \bar{b}, \gamma_r]] + \Var[\Exp[b_r | q_{kr}, \bar{b}, \gamma_r]] = \phi_l^2 q_{kr} + \bar{b}^2 q_{kr} (1-q_{kr})
%\]
%\[
%{\rm Cov}[b_r, b_{r'} \; | \; q_{kr}, q_{kr'}, \bar{b}] = 0
%\]
%And then we integrate out $\bar{b}$:
%\[
%\Exp[b_r \; | \; q_{kr}] = 0
%\]
%\[
%\Var[b_r \; | \; q_{kr}] = \phi_l^2 q_{kr} + q_{kr}^2 \omega_l^2
%\]
%\[
%\Cov[b_r, b_{r'} \; | \; q_{kr}, q_{kr'}] = q_{kr} q_{kr'} \omega_l^2
%\]
%The target distribution $\bm{b} | \bm{q}_k$ can thus be approximated by the $\Norm_R(0,U_k)$ where:
%\[
%U_k = 
%\begin{pmatrix}
%  q_{k1} (\phi_l^2 + q_{k1} \omega_l^2) & \cdots & q_{k1} q_{kR} \omega_l^2 \\
%  \vdots & \ddots & \vdots \\
%  \cdots & \cdots & q_{kR} (\phi_l^2 + q_{kR} \omega_l^2)
%\end{pmatrix}
%\]
%This approximation should be more and more accurate as $R$ increases.
%
%With this prior for $\bm{b}|\bm{q}_k$, we can directly use the approximated Bayes factor from Wen (Biometrics 2014):
%\begin{equation}
%  \label{abf_gpkl_wen}
%  \BF_{gpkl}(\bm{q}_k, \omega_l,\phi_l) = |I + \hat{V}^{-1} W_k|^{-\frac{1}{2}} \exp \left( \frac{1}{2} \hat{\bm{\beta}}^T \hat{V}^{-1} \left[ W_k (I + \hat{V}^{-1} W_k)^{-1} \right] \hat{V}^{-1} \hat{\bm{\beta}} \right)
%\end{equation}
%where $\hat{\bm{\beta}}$ is the MLE for $\bm{\beta}$ and $\hat{V}$ its variance.
%In the scale-invariance formulation, we have $\bm{b} = diag(\Sigma)^{-\frac{1}{2}} \bm{\beta}$, so that $\bm{b}|\bm{q}_k \sim \Norm_R(\bm{0}, U_k)$ induces the prior $\bm{\beta}|\bm{q}_k \sim \Norm_R(\bm{0}, W_k)$ where $W_k = diag(\Sigma)^{-\frac{1}{2}} U_k diag(\Sigma)^{-\frac{1}{2}}$.
%
%However, the remaining issue is to calculate the derivative of the log of this Bayes factor w.r.t. $\bm{q}_k$ in the M step of the EM algorithm (see below).
%
%
%\subsection{Solution 2: condition on the average effect instead of its prior variance}
%
%Matthew proposed to calculate a new Bayes factor conditional on $(\bar{b}_{gpl},\phi_l)$ instead of $(\omega_l,\phi_l)$:
%\begin{equation}
%  \begin{aligned}
%    \BF_{gpkl}(\bm{q}_k, \omega_l, \phi_l) &= \frac{\int p(\bar{b}_{gpl}) \; p(Y_g | \Xv_{gp}, t_{gpk}=1, d_{gpl}=1, \bar{b}_{gpl}) \; \der \bar{b}_{gpl}}{p(Y_g | \Xv_{gp}, z_g=0)} \\
%  \end{aligned}
%\end{equation}
%
%The idea comes from the assumptions that, given the type, the $\gamma_r$'s are independent and, given $\bar{b}$, the $b_r$ are also independent (note that we also have to assume that the errors are independent between tissues):
%\begin{equation}
%  \begin{aligned}
%    \BF_{gpkl}(\bm{q}_k, \omega_l, \phi_l) &= \frac{\int p(\bar{b}_{gpl}) \; \prod_r p(\yv_{gr} | \Xv_{gp}, t_{gpk}=1, d_{gpl}=1, \bar{b}_{gpl}) \; \der \bar{b}_{gpl}}{\prod_r p(\yv_{gr} | \Xv_{gp}, z_g=0)} \\
%    &= \frac{\int p(\bar{b}_{gpl}) \; \prod_r [ q_{kr} p(\yv_{gr} | \Xv_{gp}, d_{gpl}=1, \bar{b}_{gpl}, \gamma_{gpr}=1) + (1-q_{kr}) p(\yv_{gr} | \Xv_{gp}, \gamma_{gpr}=0) ] \; \der \bar{b}_{gpl}}{\prod_r p(\yv_{gr} | \Xv_{gp}, z_g=0)} \\
%    &= \int_{-\infty}^{+\infty} f(\bar{b}_{gpl}, \bm{q}_k, \omega_l, \phi_l) \; \der \bar{b}_{gpl}
%  \end{aligned}
%\end{equation}
%where the function $f$ is defined as:
%\begin{equation}
%  \begin{aligned}
%    f(\bar{b}_{gpl}, \bm{q}_k, \omega_l, \phi_l) &= \frac{1}{\omega_l \sqrt{2\pi}} \exp \left( -\frac{1}{2} \left( \frac{\bar{b}_{gpl}}{\omega_l} \right)^2 \right) \; \prod_r \left[ q_{kr} \BF_{gplr}(\bar{b}_{gpl}, \phi_l) + (1 - q_{kr}) \right]
%  \end{aligned}
%\end{equation}
%
%This integral can't be analytically calculated but it is unidimensional and should thus be efficiently approximated numerically, e.g. with QAGI as implemented in the \href{https://www.gnu.org/software/gsl/manual/html_node/QAGI-adaptive-integration-on-infinite-intervals.html}{GSL}.
%
%The goal now is to calculate $\BF_{gplr}$ which effectively test $b_{gplr} \sim \Norm(\bar{b}_{gpl}, \phi_l^2)$ versus $b_{gplr} \sim \Norm(0,0)$.
%As we need to focus only on a single gene-snp pair in a single tissue, we will ignore indices $g$, $p$, $l$ and $r$ in the remaining of this section.
%Moreover, we will heavily borrow from the appendices of two papers, Wen \& Stephens (2014) and Wen (2014).
%
%For one individual, we model its expression level $y_i$ at the gene as
%\begin{equation}
%  \begin{aligned}
%    y_i = \mu + \beta g_i + \epsilon_i \text{ with } \epsilon_i \sim \Norm(0,\tau^{-1})
%    \label{lik_ind}
%  \end{aligned}
%\end{equation}
%where $g_i$ is the genotype at the SNP.
%
%To have a notation similar to the articles mentioned above, we will replace the scalar $\mu$ by $\beta_c$, and similarly $\beta$ by $\beta_g$.
%As there can be other covariates (e.g. sex), we will rather use the vector notation $\bm{\beta}_c := \beta_c$ and $\bm{\beta}_g := \beta_g$.
%These vectors are gathered into $\bm{\beta} := (\bm{\beta}_c \; \bm{\beta}_g)^T$.
%Concerning the design matrix, we will use the $N \times 2$ matrix $X := (X_c \; X_g)$ where $X_c := \bm{1}$ and $X_g := \bm{g}$.
%
%As a result, equation \eqref{lik_ind} can be written as:
%\begin{equation}
%  \begin{aligned}
%    \yv = X \bm{\beta} + \bm{\epsilon} \text{ with } \bm{\epsilon} \sim \Norm_N(0,\tau^{-1} I)
%  \end{aligned}
%\end{equation}
%
%For reasons detailed in the protocol S1 of Servin \& Stephens (2007), we now shift to the ``exchangeable-standardized''model (ES model in Wen \& Stephens, 2014).
%Let's define $\tilde{\bm{y}} := \sqrt{\tau}\bm{y}$ and $\bm{b} = \sqrt{\tau} \bm{\beta}$.
%Under the full model, the likelihood is
%\begin{equation}
%  \begin{aligned}
%    p(\bm{y} | X, \tau, \bm{\beta}) = p(\bm{y} | X, \tau, \bm{b}) \propto \exp \left( -\frac{1}{2} (\tilde{\bm{y}} - X \bm{b})^T (\tilde{\bm{y}} - X \bm{b}) \right)
%    \label{lik_es_full}
%  \end{aligned}
%\end{equation}
%Using the maximum likelihood estimate $\hat{\bm{b}} := (\hat{b}_c \; \hat{b}_g)^T$ allows to reformulate \eqref{lik_es_full} using
%\begin{equation}
%  \begin{aligned}
%    (\tilde{\bm{y}} - X \bm{b})^T (\tilde{\bm{y}} - X \bm{b}) = (\tilde{\bm{y}} - X \hat{\bm{b}})^T (\tilde{\bm{y}} - X \hat{\bm{b}}) + (\bm{b} - \hat{\bm{b}})^T X^T X (\bm{b} - \hat{\bm{b}})
%    \label{lik_es_full_ker}
%  \end{aligned}
%\end{equation}
%Similarly, for the null model (i.e. full model without the genotype), the likelihood is
%\begin{equation}
%  \begin{aligned}
%    p(\bm{y} | X_c, \tau, \bm{\beta}_c) = p(\bm{y} | X_c, \tau, \bm{b}_c) \propto \exp \left( -\frac{1}{2} (\tilde{\bm{y}} - X_c \bm{b}_c)^T (\tilde{\bm{y}} - X_c \bm{b}_c) \right)
%    \label{lik_es_null}
%  \end{aligned}
%\end{equation}
%and defining $\hat{\bm{b}}_0 := (\hat{b}_0)^T$ gives
%\begin{equation}
%  \begin{aligned}
%    (\tilde{\bm{y}} - X_c \bm{b}_c)^T (\tilde{\bm{y}} - X_c \bm{b}_c) = (\tilde{\bm{y}} - X_c \hat{\bm{b}}_0)^T (\tilde{\bm{y}} - X_c \hat{\bm{b}}_0) + (\bm{b}_c - \hat{\bm{b}}_0)^T X_c^T X_c (\bm{b}_c - \hat{\bm{b}}_0)
%    \label{lik_es_null_ker}
%  \end{aligned}
%\end{equation}
%However, note that $\hat{b}_0 \neq \hat{b}_c$.
%Indeed, for the full model, the Normal equation is $X^T X \hat{\bm{b}} = X^T \tilde{\bm{y}}$ whereas for the null model the Normal equation is $X_c^T X_c \hat{\bm{b}}_0 = X_c^T \tilde{\bm{y}}$, yielding
%\begin{equation}
%  \begin{aligned}
%    \hat{b}_0 &= \hat{b}_c + (X_c^T X_c)^{-1} X_c^T X_g \hat{b}_g
%    \label{mle_es_null}
%  \end{aligned}
%\end{equation}
%
%To test the effect of the SNP, we use the Bayes factor
%\begin{equation}
%  \begin{aligned}
%    \BF(\bar{b},\phi) = \frac{\int p(\tau) \left( \int p(\bm{y}|X,\tau,\bm{b}) \; p(\bm{b}|\tau,\bm{\bar{b}},\phi) \; \der \bm{b} \right) \der \tau}{\int p(\tau) \left( \int p(\bm{y}|X_c,\tau,\bm{b}_c) \; p(\bm{b}_c|\tau) \; \der \bm{b}_c \right) \der \tau}
%    \label{BF_init}
%  \end{aligned}
%\end{equation}
%for which the prior on $\bm{b}$ under the alternative is
%\begin{equation}
%  \begin{aligned}
%    p(\bm{b}|\tau,\bm{\bar{b}},\phi) = (2\pi)^{-1} |\Phi|^{-1/2} \exp \left( -\frac{1}{2} (\bm{b} - \bm{\bar{b}})^T \Phi^{-1} (\bm{b} - \bm{\bar{b}}) \right)
%    \label{prior_b_alt}
%  \end{aligned}
%\end{equation}
%where $\Phi := diag(v^2, \phi^2)$.
%In terms of notation, we will also use $v^2 := \Phi_c$ and $\phi^2 := W_g$.
%The prior on $\tau$ is conjuguate
%\begin{equation}
%  \begin{aligned}
%    p(\tau) = \frac{(\frac{l}{2})^{\frac{m}{2}}}{\Gamma(\frac{m}{2})} \tau^{\frac{m}{2}-1} \exp \left( -\frac{l}{2}\tau \right)
%    \label{prior_tau}
%  \end{aligned}
%\end{equation}
%See the articles cited above for the other, less important priors.
%
%The first step to compute the Bayes factor \eqref{BF_init} is to integrate $\bm{b}$ using its prior \eqref{prior_b_alt}:
%\begin{equation}
%  \begin{aligned}
%F_a = \int M_a \; \der \bm{b} \text{ where } M_a = p(\bm{b}|\tau,\bm{\bar{b}},\phi) \; p(\bm{y}|X,\tau,\bm{b})
%  \end{aligned}
%\end{equation}
%Keeping only the terms in $\bm{b}$
%\begin{equation}
%  \begin{aligned}
%    M_a \propto \exp ( \bm{b}^T \Phi^{-1} \bm{b} - \bm{b}^T \Phi^{-1} \bm{\bar{b}} - \bm{\bar{b}}^T \Phi^{-1} \bm{b} ) \times \exp ( \bm{b}^T X^T X \bm{b} - \bm{b}^T X^T X \hat{\bm{b}} - \hat{\bm{b}}^T X^T X \bm{b} )
%  \end{aligned}
%\end{equation}
%Factorizing:
%\begin{equation}
%  \begin{aligned}
%    M_a \propto \exp ( \bm{b}^T ( \Phi^{-1} + X^T X ) \bm{b} - (\bm{\bar{b}}^T \Phi^{-1} + \hat{\bm{b}}^T X^T X) \bm{b} - \bm{b}^T (\Phi^{-1} \bm{\bar{b}} + X^T X \hat{\bm{b}}) )
%  \end{aligned}
%\end{equation}
%Introducing the matrix $\Omega=(\Phi^{-1} + X^TX)^{-1}$ as in Servin \& Stephens (2007), which is symmetric (i.e. $\Omega^T=\Omega \Rightarrow \Omega^{-1}\Omega^T=I$), and ``completing the square'' gives:
%\begin{equation}
%  \begin{aligned}
%    M_a &\propto \exp ( (\bm{b} - \Omega(\Phi^{-1} \bm{\bar{b}} + X^T X \hat{\bm{b}}))^T \Omega^{-1} (\bm{b} - \Omega(\Phi^{-1} \bm{\bar{b}} + X^T X \hat{\bm{b}})) ) \\
%    &\times \exp ( - (\Phi^{-1} \bar{\bm{b}} + X^T X \hat{\bm{b}})^T \Omega (\Phi^{-1} \bar{\bm{b}} + X^T X \hat{\bm{b}}) )
%  \end{aligned}
%\end{equation}
%Recognizing the first exponential as the kernel of a Normal distribution which must integrate to 1, re-adding the terms not depending on $\bm{b}$ and factorizing, we get:
%\begin{equation}
%  \begin{aligned}
%    F_a &= \left(\frac{2\pi}{\tau}\right)^{-N/2} |\Phi|^{-1/2} |\Omega|^{1/2} \exp \left[-\frac{1}{2} (\tilde{\bm{y}} -X \hat{\bm{b}})^T (\tilde{\bm{y}} -X \hat{\bm{b}}) \right] \\
%    &\times \exp \left[-\frac{1}{2} (\hat{\bm{b}}^T X^T X ((X^T X)^{-1} - \Omega) X^T X \hat{\bm{b}} + \bar{\bm{b}}^T \Phi^{-1} (\Phi - \Omega) \Phi^{-1} \bar{\bm{b}} -2 \bar{\bm{b}}^T \Phi^{-1} \Omega X^T X \hat{\bm{b}}) \right]
%  \end{aligned}
%\end{equation}
%Similarly for the null
%\begin{equation}
%  \begin{aligned}
%    F_0 &= \left(\frac{2\pi}{\tau}\right)^{-N/2} |\Phi_0|^{-1/2} |\Omega_0|^{1/2} \exp \left[-\frac{1}{2} (\tilde{\bm{y}} -X_c \hat{\bm{b}}_0)^T (\tilde{\bm{y}} -X_c \hat{\bm{b}}_0) \right] \\
%    &\times \exp \left[-\frac{1}{2} (\hat{\bm{b}}_0^T X_c^T X_c ((X_c^T X_c)^{-1} - \Omega_0) X_c^T X_c \hat{\bm{b}}_0) \right]
%  \end{aligned}
%\end{equation}
%
%The second step to compute the Bayes factor \eqref{BF_init} is to integrate $\tau$ using its prior \eqref{prior_tau} while taking the limits $v^2 \to +\infty$ and $l,m \to 0$, as in Servin \& Stephens (2007):
%\begin{equation}
%  \begin{aligned}
%    \BF(\bar{b},\phi) = \lim \frac{\int p(\tau) \; F_a \; \der \tau}{\int p(\tau) \; F_0 \; \der \tau} = \frac{\int K_a \; \der \tau}{\int K_0 \; \der \tau} \; \times \; \lim \frac{|\Phi|^{-1/2}}{|\Phi_0|^{-1/2}} \; \frac{|\Omega|^{1/2}}{|\Omega_0|^{1/2}}
%    \label{BF_lim}
%  \end{aligned}
%\end{equation}
%Let us first take care of the second term. Given the definition of $\Phi$, we have
%\[
%|\Phi|^{-1/2} = \frac{1}{v} \; \frac{1}{\phi}
%\]
%and
%\[
%|\Phi_0|^{-1/2} = \frac{1}{v}
%\]
%Given the definition of $\Omega$, we have
%\begin{equation}
%  \begin{aligned}
%    \Omega &=
%    \left(
%      \begin{pmatrix}
%        \frac{1}{v^2} & 0 \\
%        0 & \frac{1}{\phi^2} \\
%      \end{pmatrix}
%      +
%      \begin{pmatrix}
%        N & N \bar{g} \\
%        N \bar{g} & \bm{g}^T \bm{g} \\
%      \end{pmatrix}
%    \right)^{-1} \\
%    &= \frac{1}{(N + \frac{1}{v^2}) (\bm{g}^T \bm{g} + \frac{1}{\phi^2}) - N^2 \bar{g}^2}
%    \begin{pmatrix}
%      \bm{g}^T \bm{g} + \frac{1}{\phi^2} & - N \bar{g} \\
%      - N \bar{g} & N + \frac{1}{v^2} \\
%    \end{pmatrix}
%  \end{aligned}
%\end{equation}
%so that
%\[
%|\Omega|^{1/2} = \sqrt{\frac{1}{(N + \frac{1}{v^2}) (\bm{g}^T \bm{g} + \frac{1}{\phi^2}) - N^2 \bar{g}^2}}
%\]
%Similarly
%\[
%\Omega_0 = \left( \frac{1}{v^2} + N \right)^{-1}
%\]
%so that
%\[
%|\Omega_0|^{1/2} = \sqrt{\frac{1}{\frac{1}{v^2} + N}}
%\]
%Recognizing the standard error of $\hat{b}_g$
%\[
%\delta^2 = \frac{1}{\bm{g}^T \bm{g} - N \bar{g}^2}
%\]
%we can obtain
%\begin{equation}
%  \begin{aligned}
%    \underset{v \to +\infty}{\lim} \frac{|\Phi|^{-1/2}}{|\Phi_0|^{-1/2}} \; \frac{|\Omega|^{1/2}}{|\Omega_0|^{1/2}} = \frac{1}{\phi} \; \sqrt{\frac{1}{\frac{1}{\delta^2} + \frac{1}{\phi^2}}} = \sqrt{\frac{\delta^2}{\delta^2 + \phi^2}}
%  \end{aligned}
%\end{equation}
%
%Going back to the Bayes factor as in \eqref{BF_lim}, let's first assume that $\tau$ is known.
%We then need a relationship between \eqref{lik_es_full_ker} and \eqref{lik_es_null_ker} (see equation 16 in the supplement of Wen, 2014):
%\begin{equation}
%  \begin{aligned}
%    & (\tilde{\bm{y}} -X_c \hat{\bm{b}}_0)^T (\tilde{\bm{y}} -X_c \hat{\bm{b}}_0) - (\tilde{\bm{y}} -X \hat{\bm{b}})^T (\tilde{\bm{y}} -X \hat{\bm{b}}) \\
%    & = - \tilde{\bm{y}}^T X_c \hat{\bm{b}}_0 - \hat{\bm{b}}_0^T X_c^T \tilde{\bm{y}} + \hat{\bm{b}}_0^T X_c^T X_c \hat{\bm{b}}_0 + \tilde{\bm{y}}^T X \hat{\bm{b}} + \hat{\bm{b}}^T X^T \tilde{\bm{y}} - \hat{\bm{b}}^T X^T X \hat{\bm{b}} \\
%    & \text{use formula \eqref{mle_es_null} to replace }\hat{\bm{b}}_0 \\
%    & = - \tilde{\bm{y}}^T X_c (\hat{\bm{b}}_c + (X_c^T X_c)^{-1} X_c^T X_g \hat{\bm{b}}_g) - (\hat{\bm{b}}_c^T + \hat{\bm{b}}_g^T X_g^T X_c (X_c^T X_c)^{-1}) X_c^T \tilde{\bm{y}} \\
%    & + (\hat{\bm{b}}_c^T + \hat{\bm{b}}_g^T X_g^T X_c (X_c^T X_c)^{-1}) X_c^T X_c (\hat{\bm{b}}_c + (X_c^T X_c)^{-1} X_c^T X_g \hat{\bm{b}}_g) \\
%    & + \tilde{\bm{y}}^T (X_c \hat{\bm{b}}_c + X_g \hat{\bm{b}}_g) + (\hat{\bm{b}}_c^T X_c^T + \hat{\bm{b}}_g^T X_g^T) \tilde{\bm{y}} \\
%    & - (\hat{\bm{b}}_c^T X_c^T + \hat{\bm{b}}_g^T X_g^T) (X_c \hat{\bm{b}}_c + X_g \hat{\bm{b}}_g) \\
%    & \text{develop and simplify} \\
%    & = - \tilde{\bm{y}}^T X_c (X_c^T X_c)^{-1} X_c^T X_g \hat{\bm{b}}_g - \hat{\bm{b}}_g^T X_g^T X_c (X_c^T X_c)^{-1} X_c^T \tilde{\bm{y}} + \hat{\bm{b}}_g^T X_g^T X_c (X_c^T X_c)^{-1} X_c^T X_g \hat{\bm{b}}_g \\
%    & + \tilde{\bm{y}}^T X_g \hat{\bm{b}}_g + \hat{\bm{b}}_g^T X_g^T \tilde{\bm{y}} - \hat{\bm{b}}_g^T X_g^T X_g \hat{\bm{b}}_g \\
%    & \text{use the Normal equation to replace $\tilde{\bm{y}}$} \\
%    & = \hat{\bm{b}}_g^T \left( X_g^T X_g - X_g^T X_c (X_c^T X_c)^{-1} X_c^T X_g \right) \hat{\bm{b}}_g \\
%  \end{aligned}
%  \phantom{\hspace{6cm}}
%\end{equation}
%Here again we can recognize the standard error of $\hat{b}_g$, this time with the vector notation
%\begin{equation}
%  \begin{aligned}
%    V_g^{-1} = X_g^T X_g - X_g^T X_c (X_c^T X_c)^{-1} X_c^T X_g
%    \label{var_bhat}
%  \end{aligned}
%\end{equation}
%Using these relationships in \eqref{BF_lim} (when assuming $\tau$ known)
%\begin{equation}
%  \begin{aligned}
%    \frac{\int K_a \; \der \tau}{\int K_0 \; \der \tau} &= \exp \left( \frac{1}{2} \left( \hat{\bm{b}}_g^T V_g^{-1} \hat{\bm{b}}_g \right) \right) \\
%    & \times \exp \left( \frac{1}{2} \left( \hat{\bm{b}}_0^T X_c^T X_c ((X_c^T X_c)^{-1} - \Omega_0) X_c^T X_c \hat{\bm{b}}_0 \right) \right) \\
%    & \times \exp \left( - \frac{1}{2} \left( \hat{\bm{b}}^T X^T X ((X^T X)^{-1} - \Omega) X^T X \hat{\bm{b}} - \bar{\bm{b}}^T \Phi^{-1} (\Phi - \Omega) \Phi^{-1} \bar{\bm{b}} +2 \bar{\bm{b}}^T \Phi^{-1} \Omega X^T X \hat{\bm{b}} \right) \right)
%  \end{aligned}
%\end{equation}
%When taking the limit on $v$, $\Omega_0 = (X_c^T X_c)^{-1}$ and the second exponential disappears.
%For the third exponential, we can use results in the appendix of Wen (2014) which, after taking the limit, give:
%\begin{equation}
%  \begin{aligned}
%    \hat{\bm{b}}^T X^T X ((X^T X)^{-1} - \Omega) X^T X \hat{\bm{b}} = \hat{\bm{b}}_g^T D \hat{\bm{b}}_g
%  \end{aligned}
%\end{equation}
%where $D = V_g^{-1} - V_g^{-1} (V_g^{-1} + W_g^{-1})^{-1} V_g^{-1}$.
%This allows the simplification
%\begin{equation}
%  \begin{aligned}
%    \hat{\bm{b}}_g^T V_g^{-1} \hat{\bm{b}}_g - \hat{\bm{b}}^T X^T X ((X^T X)^{-1} - \Omega) X^T X \hat{\bm{b}} &= \hat{\bm{b}}_g^T V_g^{-1} (V_g^{-1} + W_g^{-1})^{-1} V_g^{-1} \hat{\bm{b}}_g \\
%    &= \frac{\hat{b}_g^2}{\delta^2} \frac{\phi^2}{\delta^2 + \phi^2}
%  \end{aligned}
%\end{equation}
%When taking the limit, we also have
%\begin{equation}
%  \begin{aligned}
%    \bar{\bm{b}}^T \Phi^{-1} \bar{\bm{b}} = \frac{\bar{b}_g^2}{\phi^2}
%  \end{aligned}
%\end{equation}
%Using the following block matrix inversion formula
%\begin{equation}
%  \begin{aligned}
%    \begin{pmatrix}
%      A & B \\
%      C & D
%    \end{pmatrix}^{-1}
%    =
%    \begin{pmatrix}
%      (A - B D^{-1} C)^{-1} & - A^{-1} B (D - C A^{-1} B)^{-1} \\
%      - D^{-1} C (A - B D^{-1} C)^{-1} & (D - C A^{-1} B)^{-1}
%    \end{pmatrix}
%  \end{aligned}
%\end{equation}
%for $\Omega$, and taking the limit, we get
%\begin{equation}
%  \begin{aligned}
%    \bar{\bm{b}}^T \Phi^{-1} \Omega \Phi^{-1} \bar{\bm{b}} &= \frac{\bar{b}_g^2}{\phi^4} ((X_g^T X_g + W_g^{-1}) - X_g^T X_c (X_c^T X_c)^{-1} X_c^T X_g)^{-1} \\
%    &= \frac{\bar{b}_g^2}{\phi^2} \frac{\delta^2}{\delta^2 + \phi^2}
%  \end{aligned}
%\end{equation}
%Similarly
%\begin{equation}
%  \begin{aligned}
%    \bar{\bm{b}}^T \Phi^{-1} \Omega X^T X \hat{\bm{b}} = \frac{\bar{b}_g \hat{b}_g}{\delta^2 + \phi^2}
%  \end{aligned}
%\end{equation}
%
%In the end, the Bayes factor is
%\begin{equation}
%  \begin{aligned}
%    \BF(\bar{b}, \phi) = \sqrt{\frac{\delta^2}{\delta^2 + \phi^2}} \exp \left( \frac{1}{2} \left( \frac{\hat{b}^2}{\delta^2} \frac{\phi^2}{\delta^2 + \phi^2} + \frac{\bar{b}^2}{\phi^2} \frac{\phi^2}{\delta^2 + \phi^2} - 2 \frac{\bar{b} \; \hat{b}}{\delta^2 + \phi^2} \right) \right)
%  \end{aligned}
%\end{equation}
%
%When $\tau$ is unknown, integrating it can't be achieved analytically.
%We hence use the Laplace's method to approximate the Bayes factor \eqref{BF_lim}.
%Following Wen (2014), we introduce $\alpha$ as mixture proportion of the weighted sum of ...
%
%TODO
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\section{Augmented likelihood}
%
%See the corresponding section in the document ``config\_model.tex/pdf''.
%
%Based on the hierarchical model described in the previous section, we can now write the augmented log-likelihood as follows,
%
%\begin{equation}
%  \begin{aligned}
%    l_a(\Theta;\Yv,\zv,\Vv,\Tv,\Dv|\Xv) &= \sum_g \log p(\Yv_g,z_g,\vv_g,T_g,D_g | \Xv_g,\Theta)
%  \end{aligned}
%\end{equation}
%
%Expanding the term inside the sum as done in the document ``config\_model.tex/pdf'', we obtain:
%\begin{equation}
% \label{laug}  
%  \begin{aligned}
%    l_a(\Theta;\Yv,\zv,\Vv,\Tv,\Dv|\Xv) &= \sum_g (1-z_g)\log \pi_0 + \sum_g z_g \log (1-\pi_0) + \sum_g \log p(Y_g|\Xv_g,z_g=0) \\
%    &+ \sum_{g,p} z_gv_{gp}\log \nu_p + \sum_{g,p,k} z_g v_{gp} t_{gpk} \log \pi_k + \sum_{g,p,l} z_g v_{gp} d_{gpl} \log \lambda_l \\
%    &+ \sum_{g,p,k,l} z_g v_{gp} t_{gpk} d_{gpl} \log \BF_{gpkl}
%  \end{aligned}
%\end{equation}
%where $\BF_{gpkl}$ is defined above \eqref{bf_gpkl}.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\section{EM algorithm}
%
%See the corresponding section in the document ``config\_model.tex/pdf''.
%
%The objective function, noted $Q$, for the EM algorithm, is:
%\begin{equation}
%  \label{Q}
%  \begin{aligned}
%    Q(\Theta|\Yv,\Xv,\Theta^{(i)}) = \Exp_{\zv,\Vv,\Tv,\Dv | \Yv,\Xv,\Theta} [ l_a(\Theta) | \Yv,\Xv,\Theta^{(i)} ]
%  \end{aligned}
%\end{equation}
%
%Starting from randomly-initialized parameters $\Theta^{(0)}$, in the E-step for the $(i+1)^{\text{th}}$ iteration, we evaluate the objective function \eqref{Q}.
%
%\begin{equation}
%  \begin{aligned}
%    \Exp[z_g | \Yv, \Xv, \Theta^{(i)}] &= \frac{(1-\pi_0^{(i)}) \BF^{(i)}_{g}}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF^{(i)}_{g}}.
%  \end{aligned}
%\end{equation}
%
%where 
%\begin{equation}
%  \begin{aligned}
%    \BF^{(i)}_{g} &= \frac{p(Y_g | \Xv_g, \Theta^{(i)}, z_g=1)}{p(Y_g | \Xv_g, z_g=0)} \\
%    &= \sum_{p,k,l} \nu_p^{(i)} \pi_k^{(i)} \lambda_l^{(i)} \BF_{gpkl}(\bm{q}_k^{(i)},\phi_l,\omega_l)
%  \end{aligned}
%\end{equation}
%
%Similarly,
%\begin{equation}
%  \begin{aligned}
%    \Exp[z_g v_{gp} | \Yv, \Xv, \Theta^{(i)}] &= \frac{(1-\pi_0^{(i)}) \nu_p^{(i)} \BF^{(i)}_{gp}}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF^{(i)}_{g}},
%  \end{aligned}
%\end{equation}
%
%where 
%\begin{equation}
%  \begin{aligned}
%    \BF^{(i)}_{gp} &= \sum_{k,l} \pi_k^{(i)} \lambda_l^{(i)} \BF_{gpkl}(\bm{q}_k^{(i)},\phi_l,\omega_l)
%  \end{aligned}
%\end{equation}
%
%And
%\begin{equation}
%  \begin{aligned}
%    \Exp[z_g v_{gp} t_{gpk} | \Yv, \Xv, \Theta^{(i)}] &= \frac{(1-\pi_0^{(i)}) \nu_p^{(i)} \pi_k^{(i)} \sum_l \lambda_l^{(i)} \BF_{gpkl}(\bm{q}_k^{(i)},\phi_l,\omega_l)}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF^{(i)}_{g}},
%  \end{aligned}
%\end{equation}
%
%\begin{equation}
%  \begin{aligned}
%    \Exp[z_g v_{gp} d_{gpl} | \Yv, \Xv, \Theta^{(i)}] &= \frac{(1-\pi_0^{(i)}) \nu_p^{(i)} \lambda_l^{(i)} \sum_k \pi_k^{(i)} \BF_{gpkl}(\bm{q}_k^{(i)},\phi_l,\omega_l)}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF^{(i)}_{g}},
%  \end{aligned}
%\end{equation}
%
%\begin{equation}
%  \begin{aligned}
%    \Exp[z_g v_{gp} t_{gpk} d_{gpl} | \Yv, \Xv, \Theta^{(i)}] = \frac{(1-\pi_0^{(i)}) \nu_p^{(i)} \pi_k^{(i)} \lambda_l^{(i)} \BF_{gpkl}(\bm{q}_k^{(i)},\phi_l,\omega_l)}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF^{(i)}_{g}}.
%  \end{aligned}
%\end{equation}
%
%
%In the M-step for the $(i+1)^{\text{th}}$ iteration, we estimate a new set of parameters, $\Theta^{(i+1)}$, by maximizing the objective function \eqref{Q}.
%
%In particular, for $\pi_0$,
%\begin{equation}
%  \begin{aligned}
%    \frac{\partial Q}{\partial \pi_0}(\pi_0^{(i+1)}) = 0 \Leftrightarrow \pi_0^{(i+1)} = \frac{1}{G} \sum_g \frac{\pi_0^{(i)}}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF_g^{(i)}}.
%  \end{aligned}
%\end{equation}
%
%For the grid points, using a Lagrange multiplier, $L_a$, to enforce the constraint,
%\begin{equation}
%  \begin{aligned}
%    \frac{\partial Q}{\partial \lambda_l}(\lambda_l^{(i+1)}) = 0 \Leftrightarrow \lambda_l^{(i+1)} = \frac{\sum_{g,p,k} \frac{\nu_p^{(i)} \pi_k^{(i)} \BF_{gpkl}(\bm{q}_k^{(i)},\phi_l,\omega_l)}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF_g^{(i)}} \cdot \lambda_l^{(i)}}{\sum_{l'} \left( \sum_{g,p,k} \frac{\nu_p^{(i)} \pi_k^{(i)} \BF_{gpkl'}(\bm{q}_k^{(i)},\phi_{l'},\omega_{l'})}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF_g^{(i)}} \cdot \lambda_{l'}^{(i)} \right)}
%  \end{aligned}
%\end{equation}
%
%Similarly, for the type proportions,
%\begin{equation}
%  \begin{aligned}
%    \pi_k^{(i+1)} = \frac{\sum_{g,p,l} \frac{\nu_p^{(i)} \lambda_l^{(i)} \BF_{gpkl}(\bm{q}_k^{(i)},\phi_l,\omega_l)}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF_g^{(i)}} \cdot \pi_k^{(i)}}{\sum_{k'} \left( \sum_{g,p,l} \frac{\nu_p^{(i)} \lambda_l^{(i)} \BF_{gpk'l}(\bm{q}_{k'}^{(i)},\phi_l,\omega_l)}{\pi_0^{(i)} + (1-\pi_0^{(i)}) \BF_g^{(i)}} \cdot \pi_{k'}^{(i)} \right)}.
%  \end{aligned}
%\end{equation}
%
%Finally, for the ``tissues per type'',
%\begin{equation}
%  \begin{aligned}
%    \frac{\partial Q}{\partial \bm{q}_k}(\bm{q}_k) = \sum_{g,p,l} \Exp[z_g v_{gp} t_{gpk} d_{gpl} | \Yv, \Xv, \Theta^{(i)}] \frac{\partial \log \BF_{gpkl}(\bm{q}_k,\phi_l,\omega_l)}{\partial \bm{q}_k}
%  \end{aligned}
%\end{equation}
%
%
%\subsection{Calculate the derivative of $\BF_{gpkl}$ w.r.t. $q_k$}
%
%If we follow William's idea, we need to derive \eqref{abf_gpkl_wen} w.r.t. $\bm{q}_k$ using rules from matrix calculus.
%
%\begin{equation}
%  \begin{aligned}
%    \frac{\partial \log \BF_{gpkl}}{\partial \bm{q}_k} &= -\frac{1}{2} \tr \left[ (I+V^{-1}W)^{-1} \frac{\partial V^{-1}W}{\partial \bm{q}_k} \right] \\
%    &+ \frac{1}{2} \ldots
%  \end{aligned}
%\end{equation}
%
%TODO
%
%
%\subsection{Calculate the derivative of $\BF_{gpkl}$ w.r.t. $q_{kr}$}
%
%If we follow Matthew's idea, we can derive $Q$ w.r.t $q_{kr}$ instead of $\bm{q}_k$:
%\begin{equation}
%  \begin{aligned}
%    \frac{\partial Q}{\partial q_{kr}}(q_{kr}) = \sum_{g,p,l} \Exp[z_g v_{gp} t_{gpk} d_{gpl} | \Yv, \Xv, \Theta^{(i)}] \frac{\partial \log \BF_{gpkl}(\bm{q}_k,\phi_l,\omega_l)}{\partial q_{kr}}
%  \end{aligned}
%\end{equation}
%where
%\begin{equation}
%  \begin{aligned}
%    \frac{\partial \log \BF_{gpkl}(\bm{q}_k,\phi_l,\omega_l)}{\partial q_{kr}} &= \frac{1}{\BF_{gpkl}(\bm{q}_k,\phi_l,\omega_l)} \frac{\partial \BF_{gpkl}(\bm{q}_k,\phi_l,\omega_l)}{\partial q_{kr}} \\
%  \end{aligned}
%\end{equation}
%
%Using \href{https://en.wikipedia.org/wiki/Leibniz_integral_rule}{Leibniz's rule}:
%\begin{equation}
%  \begin{aligned}
%    \frac{\partial \log \BF_{gpkl}(\bm{q}_k,\phi_l,\omega_l)}{\partial q_{kr}} &= \frac{1}{\int f(\bar{b}_{gpl}, \bm{q}_k,\phi_l,\omega_l) \; \der \bar{b}_{gpl}} \int \frac{\partial f(\bar{b}_{gpl}, \bm{q}_k,\phi_l,\omega_l)}{\partial q_{kr}} \; \der \bar{b}_{gpl}
%  \end{aligned}
%\end{equation}
%
%However, what should we do with the $q_{kr'}$'s where $r' \ne r$?
%
%TODO
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\section{Posteriors on latent variables}
%
%See the corresponding section in the document ``config\_model.tex/pdf''.
%
%Moreover, we may still want to assess the magnitude of eQTL sharing between tissues in terms of configurations.
%We can do that as in the config model by obtaining point estimates of each configuration probability:
%\begin{equation}
%  \hat{\eta}_j = p(\bm{\gamma}_j | \hat{\bm{\pi}}, \hat{\bm{q}}) = \sum_{k=1}^K \hat{\pi}_k \, \left[ \, \prod_{r=1}^R \hat{q}_{kr}^{\gamma_r} (1 - \hat{q}_{kr})^{1 - \gamma_r} \right]
%\end{equation}
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\section{Posteriors on genotype effect sizes}
%
%See the corresponding section in the document ``config\_model.tex/pdf''.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\section{Prior on types}
%
%In order to simulate data, we may find it useful to have a prior on types.
%Similarly to the F model in population genetics (Balding and others), we can assume that all types are related to an "ancestral" type via a star tree which edges differ.
%By changing the length of the edges, we can make the types more or less different from each other.
%Tim has some R code to compare ``config'' and ``type'' models on simulated data.
%
\end{document}
